# Using PySpark for Big Data Analytics

<p id="PySpark_Certificate" align="center">

<img src="PySpark_Certificate.png"  width="600"  height="600">
    
</p>
Analyzed over **13 million rows** (13,758,905) of music listening data using **PySpark** on **Google Colab**.  
This project demonstrates how distributed data processing can efficiently handle big data tasks such as cleaning, querying, joining, and visualizingâ€” all at scale, using Google Colab.

---

## âš¡ Skills Applied

- Big data analytics using **PySpark**
- Data cleaning & transformation
- SQL-style queries and aggregations
- Joining datasets
- Visualizing results with **Matplotlib**
- Working in **Google Colab** cloud environment

---

## Dataset

- `listenings.csv` â€“ User listening history (13M+ rows)
- `genre.csv` â€“ Artist-genre mapping

---

## Tasks Overview

### âœ… Task 1: Setup
- Mounted Google Drive
- Installed PySpark
- Created Spark session

### âœ… Task 2: Load & Explore Data
- Loaded `listenings.csv`
- Checked schema and null values
- Dropped `date` column
- Removed null records
- Verified shape (~13.7M rows)

### âœ… Task 3: Queries on Main Dataset
- Filtered listening history by artist (e.g., Rihanna)
- Found top users, top tracks, and top albums
- Aggregated listening behavior

### âœ… Task 4: Merge Datasets
- Loaded `genre.csv`
- Performed **inner join** on `artist` to enrich data with genre info

### âœ… Task 5: Genre Analytics
- Identified usersâ€™ favorite genres (using `Window` & `Struct` methods)
- Counted artists per genre (pop, rock, metal, hip hop)
- Visualized genre-wise artist distribution with bar chart

---

## Certificate

*Certificate of Completion from Coursera*  
*(Add a link or image if desired)*

---

## ðŸ“‚ Project Structure

